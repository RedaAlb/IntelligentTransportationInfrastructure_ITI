{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "\n",
    "from tensorflow.keras import callbacks, optimizers\n",
    "from yolov4.tf import SaveWeightsCallback, YOLOv4\n",
    "import time\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from datasets.datasets_utils import DatasetsUtils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert annotations to YOLOv4 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_utils = DatasetsUtils()\n",
    "\n",
    "# Directories and prefixes\n",
    "\n",
    "datasets_prefix = \"../datasets/\"\n",
    "vehicles_cropped_dir = f\"{datasets_prefix}vehicles_cropped\"\n",
    "\n",
    "\n",
    "# Generating annotation files compatible with YOLOv4 for all datasets.\n",
    "all_anno_files = []\n",
    "\n",
    "\n",
    "for i, dataset in enumerate(data_utils.datasets):\n",
    "    anno_file_path = data_utils.generate_lp_det_data(i, vehicles_cropped_dir, prefix=datasets_prefix)\n",
    "    all_anno_files.append(anno_file_path)\n",
    "    print(i, dataset, \"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_anno_files\n",
    "\n",
    "all_splitted_anno = []\n",
    "for anno_file in all_anno_files:\n",
    "    \n",
    "    if anno_file is not None:\n",
    "        train, val, test = data_utils.split_dataset(anno_file, train=70, val=20)  # The rest will be test set.\n",
    "        all_splitted_anno.append((train, val, test))\n",
    "        \n",
    "        \n",
    "    \n",
    "    print(anno_file)\n",
    "\n",
    "# Adding fixed split dataset.\n",
    "all_splitted_anno.append((f\"{vehicles_cropped_dir}/ufpr_alpr/training/ufpr_alpr_yolo_anno.txt\",\n",
    "                          f\"{vehicles_cropped_dir}/ufpr_alpr/validation/ufpr_alpr_yolo_anno.txt\",\n",
    "                          f\"{vehicles_cropped_dir}/ufpr_alpr/testing/ufpr_alpr_yolo_anno.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_splitted_anno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining all train, val, and test sets of all datasets.\n",
    "train_annos = []\n",
    "val_annos = []\n",
    "test_annos = []\n",
    "\n",
    "for splitted_anno in all_splitted_anno:\n",
    "    train_annos.append(splitted_anno[0])\n",
    "    val_annos.append(splitted_anno[1])\n",
    "    test_annos.append(splitted_anno[2])\n",
    "\n",
    "\n",
    "train_anno_file = data_utils.combine_anno_files(train_annos, datasets_prefix, \"all_train.txt\")\n",
    "val_anno_file = data_utils.combine_anno_files(val_annos, datasets_prefix, \"all_val.txt\")\n",
    "test_anno_file = data_utils.combine_anno_files(test_annos, datasets_prefix, \"all_test.txt\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_anno_file\n",
    "val_anno_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing YOLOv4 annotation format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "\n",
    "from tensorflow.keras import callbacks, optimizers\n",
    "from yolov4.tf import SaveWeightsCallback, YOLOv4\n",
    "import time\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from datasets.datasets_utils import DatasetsUtils\n",
    "\n",
    "\n",
    "data_utils = DatasetsUtils()\n",
    "\n",
    "# imgs_prefix = \"test/dataset/val2017/\"\n",
    "# class_names_file = \"test/dataset/coco.names\"\n",
    "# anno_file = \"test/dataset/val2017.txt\"\n",
    "\n",
    "imgs_prefix = \"\"\n",
    "class_names_file = \"../datasets/class.names\"\n",
    "anno_file = \"../datasets/all_train.txt\"\n",
    "\n",
    "# data_utils.check_yolov4_annos(imgs_prefix, class_names_file, anno_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(yolo.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Model and weights file do not match.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-f514559cda02>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0myolo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactivation1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"relu\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m yolo.load_weights(\"weights/yolov4-tiny.weights\",\n\u001b[1;32m---> 13\u001b[1;33m                   weights_type=\"yolo\")\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\yolov4\\tf\\__init__.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, weights_path, weights_type)\u001b[0m\n\u001b[0;32m     88\u001b[0m         \"\"\"\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mweights_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"yolo\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m             \u001b[0mweights\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtiny\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtiny\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mweights_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"tf\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\yolov4\\tf\\weights.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(model, weights_file, tiny)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Model and weights file do not match.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Model and weights file do not match."
     ]
    }
   ],
   "source": [
    "datasets_prefix = \"../datasets/\"\n",
    "\n",
    "\n",
    "yolo = YOLOv4(tiny=True)\n",
    "# yolo.classes = f\"{datasets_prefix}class.names\"\n",
    "yolo.classes = class_names_file\n",
    "\n",
    "yolo.input_size = 608\n",
    "yolo.batch_size = 1\n",
    "\n",
    "yolo.make_model(activation1=\"relu\")\n",
    "yolo.load_weights(\"weights/yolov4-tiny.weights\",\n",
    "                  weights_type=\"yolo\")\n",
    "\n",
    "\n",
    "train_data_set = yolo.load_dataset(\n",
    "    anno_file,\n",
    "    image_path_prefix=imgs_prefix,\n",
    "    label_smoothing=0.05\n",
    ")\n",
    "val_data_set = yolo.load_dataset(\n",
    "    anno_file,\n",
    "    image_path_prefix=imgs_prefix,\n",
    "    training=False\n",
    ")\n",
    "\n",
    "\n",
    "# train_data_set = yolo.load_dataset(f\"{datasets_prefix}all_train.txt\",\n",
    "#                                   image_path_prefix=\"\",\n",
    "#                                   label_smoothing=0.05)\n",
    "\n",
    "# val_data_set = yolo.load_dataset(f\"{datasets_prefix}all_val.txt\",\n",
    "#                                   image_path_prefix=\"\",\n",
    "#                                   training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YOLOv4?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "lr = 1e-4\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=lr)\n",
    "yolo.compile(optimizer=optimizer, loss_iou_type=\"ciou\")\n",
    "\n",
    "def lr_scheduler(epoch):\n",
    "    if epoch < int(epochs * 0.5):\n",
    "        return lr\n",
    "    if epoch < int(epochs * 0.8):\n",
    "        return lr * 0.5\n",
    "    if epoch < int(epochs * 0.9):\n",
    "        return lr * 0.1\n",
    "    return lr * 0.01\n",
    "\n",
    "_callbacks = [\n",
    "    callbacks.LearningRateScheduler(lr_scheduler),\n",
    "    callbacks.TerminateOnNaN(),\n",
    "    callbacks.TensorBoard(\n",
    "        log_dir=\"test/logs\",\n",
    "    ),\n",
    "    SaveWeightsCallback(\n",
    "        yolo=yolo, dir_path=\"test/saved_weights\",\n",
    "        weights_type=\"yolo\", epoch_per_save=100\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "his = yolo.fit(\n",
    "    train_data_set,\n",
    "    epochs=epochs,\n",
    "    callbacks=_callbacks,\n",
    "    validation_data=val_data_set,\n",
    "    validation_steps=50,\n",
    "    validation_freq=5,\n",
    "    steps_per_epoch=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf_gpu] *",
   "language": "python",
   "name": "conda-env-tf_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
